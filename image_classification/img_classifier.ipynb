{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set image size\n",
    "img_size = (299, 299)\n",
    "\n",
    "# Resize images in abandoned houses folder\n",
    "for filename in os.listdir('abandoned_houses'):\n",
    "    img = Image.open(os.path.join('abandoned_houses', filename))\n",
    "    img = img.resize(img_size)\n",
    "    img.save(os.path.join('abandoned_houses_resized', filename))\n",
    "\n",
    "# Resize images in regular houses folder\n",
    "for filename in os.listdir('regular_houses'):\n",
    "    img = Image.open(os.path.join('regular_houses', filename))\n",
    "    img = img.resize(img_size)\n",
    "    img.save(os.path.join('regular_houses_resized', filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8873b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class HouseDataset:\n",
    "    def __init__(self, data_dir, img_size):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.class_names = ['abandoned', 'regular']\n",
    "\n",
    "    def load_data(self):\n",
    "        abandoned_files = [os.path.join(self.data_dir, 'abandoned_houses_resized', f) for f in os.listdir(os.path.join(self.data_dir, 'abandoned_houses_resized'))]\n",
    "        regular_files = [os.path.join(self.data_dir, 'regular_houses_resized', f) for f in os.listdir(os.path.join(self.data_dir, 'regular_houses_resized'))]\n",
    "\n",
    "        all_files = abandoned_files + regular_files\n",
    "        labels = [0] * len(abandoned_files) + [1] * len(regular_files)\n",
    "\n",
    "        return all_files, labels\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.img_size)\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "\n",
    "    def create_dataset(self):\n",
    "        files, labels = self.load_data()\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((files, labels))\n",
    "        dataset = dataset.map(lambda x, y: (self.preprocess_image(x), y))\n",
    "        return dataset.batch(32)  # batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a9edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012a6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957bc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HouseDataset('path/to/data', (299, 299)).create_dataset()\n",
    "history = model.fit(dataset, epochs=10, validation_data=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, F1Score, AUC\n",
    "\n",
    "precision = Precision()\n",
    "recall = Recall()\n",
    "f1_score = F1Score()\n",
    "auc = AUC()\n",
    "\n",
    "test_dataset = HouseDataset('path/to/test/data', (299, 299)).create_dataset()\n",
    "\n",
    "model.evaluate(test_dataset)\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_true = [y for x, y in test_dataset]\n",
    "\n",
    "precision.update_state(y_true, y_pred)\n",
    "recall.update_state(y_true, y_pred)\n",
    "f1_score.update_state(y_true, y_pred)\n",
    "auc.update_state(y_true, y_pred)\n",
    "\n",
    "print(f'Test precision: {precision.result().numpy():.3f}')\n",
    "print(f'Test recall: {recall.result().numpy():.3f}')\n",
    "print(f'Test F1-score: {f1_score.result().numpy():.3f}')\n",
    "print(f'Test AUC-ROC: {auc.result().numpy():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Set image size\n",
    "img_size = (299, 299)\n",
    "\n",
    "# Create dataset class\n",
    "class HouseDataset:\n",
    "    def __init__(self, data_dir, img_size):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.class_names = ['abandoned', 'regular']\n",
    "\n",
    "    def load_data(self):\n",
    "        abandoned_files = [os.path.join(self.data_dir, 'abandoned_houses', f) for f in os.listdir(os.path.join(self.data_dir, 'abandoned_houses'))]\n",
    "        regular_files = [os.path.join(self.data_dir, 'regular_houses', f) for f in os.listdir(os.path.join(self.data_dir, 'regular_houses'))]\n",
    "\n",
    "        all_files = abandoned_files + regular_files\n",
    "        labels = [0] * len(abandoned_files) + [1] * len(regular_files)\n",
    "\n",
    "        return all_files, labels\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.img_size)\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "\n",
    "    def create_dataset(self, files, labels, batch_size=32):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((files, labels))\n",
    "        dataset = dataset.map(lambda x, y: (self.preprocess_image(x), y))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset\n",
    "\n",
    "# Load data\n",
    "'''\n",
    "supposed data structure\n",
    "data/\n",
    "abandoned_houses/\n",
    "image1.jpg\n",
    "image2.jpg\n",
    "...\n",
    "regular_houses/\n",
    "image1.jpg\n",
    "image2.jpg\n",
    "...\n",
    "'''\n",
    "data_dir = 'path/to/data'\n",
    "dataset = HouseDataset(data_dir, img_size)\n",
    "all_files, labels = dataset.load_data()\n",
    "\n",
    "# Split data into train, test, and dev sets\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(all_files, labels, test_size=0.2, random_state=42)\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(val_files, val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_dataset = dataset.create_dataset(train_files, train_labels, batch_size=32)\n",
    "val_dataset = dataset.create_dataset(val_files, val_labels, batch_size=32)\n",
    "test_dataset = dataset.create_dataset(test_files, test_labels, batch_size=32)\n",
    "\n",
    "# Load pre-trained InceptionV3 model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Freeze some layers and add a new classification head\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test loss: {test_loss:.3f}, Test accuracy: {test_acc:.3f}')\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Evaluate metrics\n",
    "y_true = test_labels\n",
    "accuracy = accuracy_score(y_true, y_pred_class)\n",
    "print(f'Test accuracy: {accuracy:.3f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred_class))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
